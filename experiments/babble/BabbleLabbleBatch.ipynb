{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'domain': 'spouse',\n",
    "    'debug': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$SNORKELDB = sqlite:///babble_spouse_debug.db\n"
     ]
    }
   ],
   "source": [
    "# Get DB connection string and add to globals\n",
    "# NOTE: $SNORKELDB must be set before any snorkel imports\n",
    "import os\n",
    "\n",
    "default_db_name = 'babble_' + config['domain'] + ('_debug' if config.get('debug', False) else '')\n",
    "DB_NAME = getattr(config, 'db_name', default_db_name)\n",
    "if 'postgres' in config and config['postgres']:\n",
    "    DB_TYPE = 'postgres'\n",
    "else:\n",
    "    DB_TYPE = 'sqlite'\n",
    "    DB_NAME += '.db'\n",
    "DB_ADDR = \"localhost:{0}\".format(config['db_port']) if 'db_port' in config else \"\"\n",
    "os.environ['SNORKELDB'] = '{0}://{1}/{2}'.format(DB_TYPE, DB_ADDR, DB_NAME)\n",
    "print(\"$SNORKELDB = {0}\".format(os.environ['SNORKELDB']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting domain=None to domain=spouse\n",
      "Overwriting init_class_prior=0 to init_class_prior=-1.15\n",
      "Overwriting reg_param=0.1 to reg_param=0.5\n",
      "Overwriting decay=0.95 to decay=0.99\n",
      "NOTE: --debug=True: modifying parameters...\n"
     ]
    }
   ],
   "source": [
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "# Resolve config conflicts (nb_config > local_config > global_config)\n",
    "from snorkel.contrib.babble.pipelines import merge_configs, get_local_pipeline\n",
    "config = merge_configs(config)\n",
    "\n",
    "if config.get('debug', False):\n",
    "    print(\"NOTE: --debug=True: modifying parameters...\")\n",
    "    config['max_docs'] = 100\n",
    "    config['gen_model_search_space'] = 1\n",
    "    config['disc_model_search_space'] = 1\n",
    "    config['gen_params_default']['epochs'] = 25\n",
    "    config['disc_params_default']['n_epochs'] = 5\n",
    "\n",
    "from snorkel.models import candidate_subclass\n",
    "candidate_class = candidate_subclass(config['candidate_name'], config['candidate_entities'])\n",
    "\n",
    "pipeline = get_local_pipeline(config['domain'])\n",
    "pipe = pipeline(session, candidate_class, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse, Extract, Load Gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "Documents: 100\n",
      "Sentences: 2785\n",
      "CPU times: user 1min 59s, sys: 3.54 s, total: 2min 2s\n",
      "Wall time: 2min 4s\n"
     ]
    }
   ],
   "source": [
    "%time pipe.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "Candidates [Split 0]: 839\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "Candidates [Split 1]: 62\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "Candidates [Split 2]: 75\n",
      "CPU times: user 14.7 s, sys: 441 ms, total: 15.1 s\n",
      "Wall time: 14.9 s\n"
     ]
    }
   ],
   "source": [
    "%time pipe.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnotatorLabels created: 8\n",
      "AnnotatorLabels created: 62\n",
      "AnnotatorLabels created: 75\n",
      "CPU times: user 48.3 s, sys: 411 ms, total: 48.7 s\n",
      "Wall time: 49 s\n"
     ]
    }
   ],
   "source": [
    "%time pipe.load_gold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Gather Explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step can be executed all at once with a single command:\n",
    "\n",
    "```pipe.collect()```\n",
    "\n",
    "Because we would like to inspect the results between each step for illustration purposes, however, we will break it up into intermediate steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load a number of pre-built lists that the user can refer to when writing explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User lists: ['known_spouses', 'spouse', 'other', 'family', 'last_names']\n"
     ]
    }
   ],
   "source": [
    "from experiments.babble.spouse.spouse_examples import get_user_lists\n",
    "user_lists = get_user_lists()\n",
    "print(\"User lists: {}\".format(user_lists.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the 'spouse' list contains a number of spouse-related words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spouse', 'wife', 'husband', 'ex-wife', 'ex-husband']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_lists['spouse']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have written 10 explanations as a starting point. We 'link' them to the candidates that they refer to by storing with each one a pointer to the candidate that the explanation was given in reference to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "candidates = session.query(candidate_class).filter(\n",
    "    candidate_class.split == config['babbler_candidate_split']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building list of target candidate ids...\n",
      "Collected 11 unique target candidate ids from 11 explanations.\n",
      "Gathering desired candidates...\n",
      "Could not find 11 target candidates with the following stable_ids (first 5):\n",
      "(0, '2ca6dbbb-870c-4e34-8053-0ac2dbd850f5::span:798:808~~2ca6dbbb-870c-4e34-8053-0ac2dbd850f5::span:839:851')\n",
      "(1, '3375a3c2-9b8a-423a-8334-32fe860be60e::span:3939:3948~~3375a3c2-9b8a-423a-8334-32fe860be60e::span:3967:3981')\n",
      "(2, '03a1e1a0-93c3-41a8-a905-a535ce8f2b09::span:6822:6837~~03a1e1a0-93c3-41a8-a905-a535ce8f2b09::span:6855:6858')\n",
      "(3, 'd0de6a86-66d5-40e0-b345-6c86d2047c07::span:1634:1638~~d0de6a86-66d5-40e0-b345-6c86d2047c07::span:1650:1659')\n",
      "(4, 'c313f020-d5f8-480f-85f5-dc639157f7e5::span:2957:2960~~c313f020-d5f8-480f-85f5-dc639157f7e5::span:3175:3178')\n",
      "Found 0/11 desired candidates\n",
      "Linking explanations to candidates...\n",
      "Linked 0/11 explanations\n"
     ]
    }
   ],
   "source": [
    "from experiments.babble.spouse.spouse_examples import get_explanations\n",
    "explanations = get_explanations(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there is a spouse word between arg 1 and arg 2\n",
      "there is a spouse word within two words to the left of arg 1 or arg 2\n",
      "there are no spouse words in the sentence\n",
      "the word 'and' is between arg 1 and arg 2 and 'married' or 'marriage' is after arg 2\n",
      "there is a family word between arg 1 and arg 2\n",
      "there is a family word within three words to the left of arg 1 or arg 2\n",
      "there is an other word between arg 1 and arg 2\n",
      "either the pair of arg 1 and arg 2 or the pair arg 2 and arg 1 is in known_spouses\n",
      "the number of words between arg 1 and arg 2 is larger than 10\n",
      "there is a person between arg 1 and arg 2\n",
      "arg 1 is identical to arg 2\n"
     ]
    }
   ],
   "source": [
    "for exp in explanations:\n",
    "    print(exp.condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Filter Bank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create a ```Babbler``` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created grammar with 480 rules\n"
     ]
    }
   ],
   "source": [
    "from snorkel.contrib.babble import Babbler\n",
    "\n",
    "babbler = Babbler(mode='text', \n",
    "                  explanations=explanations, \n",
    "                  candidate_class=candidate_class, \n",
    "                  user_lists=user_lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No we use our semantic parser to convert the explanations into labeling functions (LFs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 parses created from 11 out of 11 explanation(s)\n",
      "Parsed 24 LFs from 11 explanations.\n"
     ]
    }
   ],
   "source": [
    "lfs = babbler.generate_lfs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the ambiguity of natural language, we have more than twice as many candidate LFs as explanations. We now apply the filters in our filter bank to remove as many spurious LFs as possible without requiring additional labels.\n",
    "\n",
    "First, if any parses have identical semantics (i.e., they represent the same program), remove all but one copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered to 20 LFs with duplicate semantics filter (4 filtered).\n"
     ]
    }
   ],
   "source": [
    "babbler.filter_duplicate_semantics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, remove any candidate LFs who label their accompanying candidate inconsistently with the label the user gave when providing the explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: 20 LFs did not have candidates and therefore could not be filtered.\n",
      "Filtered to 20 LFs with consistency filter (0 filtered).\n"
     ]
    }
   ],
   "source": [
    "babbler.filter_consistency()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply the remaining LFs to the full candidate set to observe their labeling signatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<839x20 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 3412 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "babbler.generate_label_matrix(split=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove any LFs that label all candidates True or all candidates False. (In this case, either no LFs of this type were generated or they were removed by previous filters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered to 17 LFs with uniform signatures filter (3 filtered).\n"
     ]
    }
   ],
   "source": [
    "babbler.filter_uniform_signatures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then remove any LFs that have a duplicate labeling signature (i.e., even though they are technically different programs, since they have different semantics, they are effectively the same in this domain and therefore provide no unique information)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered to 12 LFs with duplicate signatures filter (5 filtered).\n"
     ]
    }
   ],
   "source": [
    "babbler.filter_duplicate_signatures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual parsed labeling functions are lambda functions ready to operate on candidates, which are hard to interpret directly. We can, however, view the explicit semantics of the remaining LFs or pseudocode versions of them (default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"return 1 if any(map(in $'known_spouses'$, [tuple([text(arg1),text(arg2)]),tuple([text(arg2),text(arg1)])])) else 0\",\n",
       " \"return -1 if any(map(in text(left(arg2,'.leq',3,'words')), $'family'$)) else 0\",\n",
       " \"return -1 if any(map(in text(left(arg1,'.leq',3,'words')), $'family'$)) else 0\",\n",
       " 'return -1 if call((= text(arg2)), text(arg1)) else 0',\n",
       " \"return 1 if (call(in text(between([arg1,arg2])), 'and') and any(map(in text(right(arg2)), ['married','marriage']))) else 0\",\n",
       " \"return -1 if call((= 0), sum(map(in text(sentence()), $'spouse'$))) else 0\",\n",
       " \"return -1 if any(map(in text(between([arg1,arg2])), $'other'$)) else 0\",\n",
       " 'return 1 if call((>= 1), count(filter(between([arg1,arg2]), words, \\\\w+\\\\S*))) else 0',\n",
       " \"return 1 if any(map(in text(left(arg2,'.leq',2,'words')), $'spouse'$)) else 0\",\n",
       " \"return 1 if any(map(in text(left(arg1,'.leq',2,'words')), $'spouse'$)) else 0\",\n",
       " 'return -1 if call((>= 1), count(filter(between([arg1,arg2]), ner_tags, PERSON))) else 0',\n",
       " 'return -1 if call((> 10), count(between([arg1,arg2]))) else 0']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "babbler.get_parses(translate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These parses correspond to the following explanations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Explanation(\"LF_distant: True, either the pair of arg 1 and arg 2 or the pair arg 2 and arg 1 is in known_spouses\"),\n",
       " Explanation(\"LF_family_to_left: False, there is a family word within three words to the left of arg 1 or arg 2\"),\n",
       " Explanation(\"LF_family_to_left: False, there is a family word within three words to the left of arg 1 or arg 2\"),\n",
       " Explanation(\"LF_identical_args: False, arg 1 is identical to arg 2\"),\n",
       " Explanation(\"LF_married_after: True, the word 'and' is between arg 1 and arg 2 and 'married' or 'marriage' is after arg 2\"),\n",
       " Explanation(\"LF_no_spouse_in_sentence: False, there are no spouse words in the sentence\"),\n",
       " Explanation(\"LF_other_between: False, there is an other word between arg 1 and arg 2\"),\n",
       " Explanation(\"LF_spouse_between: True, there is a spouse word between arg 1 and arg 2\"),\n",
       " Explanation(\"LF_spouse_to_left: True, there is a spouse word within two words to the left of arg 1 or arg 2\"),\n",
       " Explanation(\"LF_spouse_to_left: True, there is a spouse word within two words to the left of arg 1 or arg 2\"),\n",
       " Explanation(\"LF_third_wheel: False, there is a person between arg 1 and arg 2\"),\n",
       " Explanation(\"LF_too_far_apart: False, the number of words between arg 1 and arg 2 is larger than 10\")]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "babbler.get_explanations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now store the results from the Babbler in the SpousePipeline object for the sake of later stages in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import LabelAnnotator\n",
    "\n",
    "pipe.babbler = babbler\n",
    "pipe.lfs = babbler.lfs\n",
    "pipe.labeler = LabelAnnotator(lfs=babbler.lfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "\n",
      "Labeled split 0: (839,12) sparse (nnz = 2461)\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "\n",
      "Labeled split 1: (62,12) sparse (nnz = 173)\n",
      "                             j  Coverage  Overlaps  Conflicts  TP  FP  FN  TN  \\\n",
      "LF_spouse_between_0          0  0.919355  0.903226   0.903226   5  52   0   0   \n",
      "LF_spouse_to_left_0          1  0.161290  0.161290   0.161290   2   8   0   0   \n",
      "LF_spouse_to_left_3          2  0.016129  0.016129   0.016129   0   1   0   0   \n",
      "LF_no_spouse_in_sentence_0   3  0.709677  0.661290   0.661290   0   0   2  42   \n",
      "LF_married_after_3           4  0.048387  0.048387   0.048387   1   2   0   0   \n",
      "LF_family_to_left_0          5  0.000000  0.000000   0.000000   0   0   0   0   \n",
      "LF_family_to_left_3          6  0.000000  0.000000   0.000000   0   0   0   0   \n",
      "LF_other_between_0           7  0.000000  0.000000   0.000000   0   0   0   0   \n",
      "LF_distant_0                 8  0.000000  0.000000   0.000000   0   0   0   0   \n",
      "LF_too_far_apart_0           9  0.548387  0.548387   0.548387   0   0   2  32   \n",
      "LF_third_wheel_0            10  0.338710  0.338710   0.338710   0   0   1  20   \n",
      "LF_identical_args_0         11  0.048387  0.032258   0.032258   0   0   0   3   \n",
      "\n",
      "                            Empirical Acc.  \n",
      "LF_spouse_between_0               0.087719  \n",
      "LF_spouse_to_left_0               0.200000  \n",
      "LF_spouse_to_left_3               0.000000  \n",
      "LF_no_spouse_in_sentence_0        0.954545  \n",
      "LF_married_after_3                0.333333  \n",
      "LF_family_to_left_0                    NaN  \n",
      "LF_family_to_left_3                    NaN  \n",
      "LF_other_between_0                     NaN  \n",
      "LF_distant_0                           NaN  \n",
      "LF_too_far_apart_0                0.941176  \n",
      "LF_third_wheel_0                  0.952381  \n",
      "LF_identical_args_0               1.000000  \n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[==========                              ] 22%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bradenjh/repos/snorkel/snorkel/annotations.py:129: RuntimeWarning: invalid value encountered in divide\n",
      "  ac = (tp+tn).astype(float) / (tp+tn+fp+fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "\n",
      "Labeled split 2: (75,12) sparse (nnz = 230)\n",
      "CPU times: user 8.28 s, sys: 233 ms, total: 8.52 s\n",
      "Wall time: 8.48 s\n"
     ]
    }
   ],
   "source": [
    "%time pipe.label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using L_train: <839x12 sparse matrix of type '<type 'numpy.int64'>'\n",
      "\twith 2461 stored elements in Compressed Sparse Row format>\n",
      "Using L_dev: <62x12 sparse matrix of type '<type 'numpy.int64'>'\n",
      "\twith 173 stored elements in Compressed Sparse Row format>\n",
      "Using L_test: <75x12 sparse matrix of type '<type 'numpy.int64'>'\n",
      "\twith 230 stored elements in Compressed Sparse Row format>\n",
      "Skipping grid search.\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] Model saved as <generative_spouse>.\n",
      "\n",
      "Gen. model (DP) score on dev set (b=0.1):\n",
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.6\n",
      "Neg. class accuracy: 0.912\n",
      "Precision            0.375\n",
      "Recall               0.6\n",
      "F1                   0.462\n",
      "----------------------------------------\n",
      "TP: 3 | FP: 5 | TN: 52 | FN: 2\n",
      "========================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12ee07d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.92 s, sys: 72.7 ms, total: 2 s\n",
      "Wall time: 2 s\n"
     ]
    }
   ],
   "source": [
    "%time pipe.supervise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping grid search.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bradenjh/repos/snorkel/snorkel/learning/disc_models/rnn/rnn_base.py:34: UserWarning: Candidate 8 has argument past max length for model:\t[arg ends at index 102; max len 100]\n",
      "  warnings.warn('\\t'.join([w.format(i), info]))\n",
      "/Users/bradenjh/repos/snorkel/snorkel/learning/disc_models/rnn/rnn_base.py:35: UserWarning: Additional warnings of this nature will be suppressed.\n",
      "  warnings.warn('Additional warnings of this nature will be suppressed.')\n",
      "/Users/bradenjh/anaconda/envs/snorkel/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py:91: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRNN] Training model\n",
      "[reRNN] n_train=92  #epochs=5  batch size=92\n",
      "[reRNN] Epoch 0 (0.24s)\tAverage loss=0.694546\tDev F1=0.00\n",
      "[reRNN] Epoch 1 (0.49s)\tAverage loss=0.654908\tDev F1=0.00\n",
      "[reRNN] Epoch 2 (0.73s)\tAverage loss=0.562504\tDev F1=0.00\n",
      "[reRNN] Epoch 3 (0.98s)\tAverage loss=0.469502\tDev F1=0.00\n",
      "[reRNN] Epoch 4 (1.22s)\tAverage loss=0.490283\tDev F1=0.00\n",
      "[reRNN] Training done (1.26s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bradenjh/repos/snorkel/snorkel/learning/disc_models/rnn/rnn_base.py:34: UserWarning: Candidate 37 has argument past max length for model:\t[arg ends at index 199; max len 100]\n",
      "  warnings.warn('\\t'.join([w.format(i), info]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRNN] Model saved as <discriminative_spouse>\n",
      "### [7.2] Evaluate generative model (opt_b=0.1)\n",
      "### Done in 0.0s.\n",
      "\n",
      "### [7.3] Evaluate discriminative model (opt_b=0.1)\n",
      "### Done in 0.2s.\n",
      "\n",
      "      Coverage  F1 Score  Precision    Recall\n",
      "Disc       1.0  0.170732   0.093333  1.000000\n",
      "Gen        1.0  0.750000   0.666667  0.857143\n",
      "CPU times: user 11.5 s, sys: 2.16 s, total: 13.7 s\n",
      "Wall time: 6.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bradenjh/repos/snorkel/snorkel/learning/disc_models/rnn/rnn_base.py:34: UserWarning: Candidate 5 has argument past max length for model:\t[arg ends at index 103; max len 100]\n",
      "  warnings.warn('\\t'.join([w.format(i), info]))\n"
     ]
    }
   ],
   "source": [
    "%time pipe.classify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to Traditional Supervision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: if running in debug mode, traditional supervision will likely fail, as there aren't enough gold labels loaded to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config['supervision'] = 'traditional'\n",
    "config['max_train'] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requested 1000 traditional labels. Using 8 instead...\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noBjCDQDFEG4AKIZwA0AxhBsAivk/k1pDVfvJ6noAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12e455910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe.supervise(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe.classify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding More Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_candidates = session.query(candidate_class).filter(\n",
    "    candidate_class.split == 0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.viewer import SentenceNgramViewer\n",
    "sv = SentenceNgramViewer(train_candidates[500:600], session, n_per_page=3, height=300)\n",
    "sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.contrib.babble import Explanation\n",
    "\n",
    "babbler.add_explanations(\n",
    "    Explanation(\n",
    "        label=False,\n",
    "        condition=\"'role as' is between arg 1 and arg 2\",\n",
    "        candidate=sv.get_selected()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
