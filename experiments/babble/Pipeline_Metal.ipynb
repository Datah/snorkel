{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'project': 'babble',\n",
    "    'domain': 'cdr',\n",
    "#     'db_name': 'babble_protein_temp4',\n",
    "    'splits': [0,1],\n",
    "    'gold_explanations': True,\n",
    "    'supervision': 'soft_majority',\n",
    "    'gen_model_search_space': 1,\n",
    "#     'gen_params_default': {\n",
    "#         'epochs': 0\n",
    "#     },\n",
    "    'tune_b': False,\n",
    "    'disc_model_class': 'logreg',\n",
    "    'disc_model_search_space': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$SNORKELDB = sqlite:///babble_cdr.db\n"
     ]
    }
   ],
   "source": [
    "# Get DB connection string and add to globals\n",
    "# NOTE: $SNORKELDB must be set before any snorkel imports\n",
    "import os\n",
    "\n",
    "default_db_name = 'babble_' + config['domain'] + ('_debug' if config.get('debug', False) else '')\n",
    "DB_NAME = config.get('db_name', default_db_name)\n",
    "if 'postgres' in config and config['postgres']:\n",
    "    DB_TYPE = 'postgres'\n",
    "else:\n",
    "    DB_TYPE = 'sqlite'\n",
    "    DB_NAME += '.db'\n",
    "DB_ADDR = \"localhost:{0}\".format(config['db_port']) if 'db_port' in config else \"\"\n",
    "os.environ['SNORKELDB'] = '{0}://{1}/{2}'.format(DB_TYPE, DB_ADDR, DB_NAME)\n",
    "print(\"$SNORKELDB = {0}\".format(os.environ['SNORKELDB']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "spaCy not installed. Use `pip install spacy`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-edf08e7f52cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Resolve config conflicts (nb_config > local_config > global_config)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msnorkel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipelines\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmerge_configs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_local_pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/bradenjh/repos/snorkel/snorkel/contrib/pipelines/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglobal_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconfig_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmerge_configs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_local_pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msnorkel_pipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSnorkelPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/bradenjh/repos/snorkel/snorkel/contrib/pipelines/snorkel_pipeline.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Snorkel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msnorkel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_subclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msnorkel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCorpusParser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTSVDocPreprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXMLMultiDocPreprocessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msnorkel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspacy_parser\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msnorkel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandidates\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNgrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCandidateExtractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/bradenjh/repos/snorkel/snorkel/parser/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage_extractors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mspacy_parser\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mrule_parser\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/bradenjh/repos/snorkel/snorkel/parser/spacy_parser.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresolve_model_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spaCy not installed. Use `pip install spacy`.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: spaCy not installed. Use `pip install spacy`."
     ]
    }
   ],
   "source": [
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "# Resolve config conflicts (nb_config > local_config > global_config)\n",
    "from snorkel.contrib.pipelines import merge_configs, get_local_pipeline\n",
    "config = merge_configs(config)\n",
    "\n",
    "from snorkel.models import candidate_subclass\n",
    "candidate_class = candidate_subclass(config['candidate_name'], config['candidate_entities'])\n",
    "\n",
    "pipeline = get_local_pipeline(config['domain'])\n",
    "pipe = pipeline(session, candidate_class, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from snorkel.annotations import load_gold_labels, load_label_matrix\n",
    "# from scipy.sparse import save_npz\n",
    "# TRAIN = 0\n",
    "# DEV = 1\n",
    "\n",
    "# L_train = load_label_matrix(pipe.session, split=TRAIN)\n",
    "# save_npz('L_train_' + config['domain'], L_train)\n",
    "\n",
    "# L_dev = load_label_matrix(pipe.session, split=DEV)\n",
    "# save_npz('L_dev_' + config['domain'], L_dev)\n",
    "\n",
    "# L_gold_dev = load_gold_labels(pipe.session, annotator_name='gold', split=DEV)\n",
    "# save_npz('L_gold_dev_' + config['domain'], L_gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %time pipe.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %time pipe.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for split in [0,1,2]:\n",
    "#     print(session.query(pipe.candidate_class).filter(\n",
    "#         pipe.candidate_class.split == split).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %time pipe.load_gold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %time pipe.featurize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %time pipe.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# log_forms = []\n",
    "# for exp in pipe.explanations:\n",
    "#     log_forms.append(str(exp.semantics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# towrite = np.array(log_forms)\n",
    "# np.save(\"protein_lfs\", towrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %time pipe.label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from snorkel.annotations import load_gold_labels, load_label_matrix\n",
    "\n",
    "# TEST = 2\n",
    "\n",
    "# L_test = load_label_matrix(pipe.session, split=TEST)\n",
    "# L_gold_test = load_gold_labels(pipe.session, annotator_name='gold', split=TEST)\n",
    "# print(L_test.lf_stats(pipe.session, labels=L_gold_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %time pipe.supervise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.hist(pipe.train_marginals)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt Metal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from snorkel.annotations import load_gold_labels, load_label_matrix\n",
    "\n",
    "# TRAIN = 0\n",
    "# DEV = 1\n",
    "\n",
    "# L_train = load_label_matrix(pipe.session, split=TRAIN)\n",
    "\n",
    "# L_dev = load_label_matrix(pipe.session, split=DEV)\n",
    "# L_gold_dev = load_gold_labels(pipe.session, annotator_name='gold', split=DEV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def convert_to_categorical(X):\n",
    "#     \"\"\"Convert {0,-1,1} -> {0,1,2}.\"\"\"\n",
    "#     X[X == 1] = 2\n",
    "#     X[X == -1] = 1\n",
    "#     return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# L_train = convert_to_categorical(L_train)\n",
    "# L_dev = convert_to_categorical(L_dev)\n",
    "# L_gold_dev = convert_to_categorical(L_gold_dev)\n",
    "\n",
    "# # Fix for weird scipy.matrix format\n",
    "# L_gold_dev = np.array(L_gold_dev.todense().T)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from metal.class_hierarchy import ClassHierarchy\n",
    "\n",
    "# task_to_lfs = {0 : range(L_train.shape[1])}\n",
    "# ch = ClassHierarchy(L_train, task_to_lfs, [], [2])\n",
    "\n",
    "# ch.grid_search_train(\n",
    "#     L_dev,\n",
    "#     L_gold_dev,\n",
    "#     search_space={\n",
    "#         'l2': [0.5], #[0.0, 0.1, 0.5, 1.0],\n",
    "# #         'step_size': [0.01], #[0.01, 0.05, 0.1, 0.25]\n",
    "#     },\n",
    "#     score_metric='f1',\n",
    "#     n_steps=500,\n",
    "#     print_at=250\n",
    "# )\n",
    "\n",
    "# prec, rec, f1 = ch.f1_score(L_dev, L_gold_dev)\n",
    "# print('DP on test set: P={} | R={} | F1={}'.format(prec, rec, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.hist(ch.LF_accs(0))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.hist(ch.conditional_probs(ch._parse_L(L_train), 0)[2])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import random\n",
    "# from scipy.sparse import csr_matrix, lil_matrix, issparse\n",
    "\n",
    "# def add_pepper(L, p=0.1):\n",
    "#     n, m = L.shape\n",
    "#     polarity = np.zeros((m,))\n",
    "#     for j in range(m):\n",
    "#         polarity[j] = 1 if np.sum(L[:,j]) >= 0 else -1\n",
    "    \n",
    "#     L = lil_matrix(L)\n",
    "#     for j in range(m):\n",
    "#         opposite = polarity[j] * -1\n",
    "#         for i in range(n):\n",
    "#             if random.random() < p and not L[i,j]:\n",
    "#                 L[i,j] = opposite\n",
    "#     return csr_matrix(L)\n",
    "\n",
    "# def to_metal_labels(L):\n",
    "#     L[L == 1] = 2\n",
    "#     L[L == -1] = 1\n",
    "#     return L\n",
    "\n",
    "# def transform_L(L_in, pepper=0):\n",
    "#     if np.max(L_in) > 1:\n",
    "#         raise Exception(\"L has already been transformed.\")\n",
    "\n",
    "#     if issparse(L_in):\n",
    "#         L = csr_matrix(L_in.copy())\n",
    "#     else:\n",
    "#         L = L_in.copy()\n",
    "        \n",
    "#     if pepper:\n",
    "#         L = add_pepper(L, p=pepper)\n",
    "        \n",
    "#     return to_metal_labels(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from metal.class_hierarchy import ClassHierarchy\n",
    "\n",
    "# N_STEPS = 500\n",
    "\n",
    "# task_to_lfs = { 0 : list(range(L_train.shape[1])) }\n",
    "# gold_dev = transform_L(np.array(L_gold_dev.todense()).T[0])\n",
    "\n",
    "# best = (0, 0, 0)\n",
    "# for p in [0, 0.05, 0.1, 0.2, 0.3]:\n",
    "#     L_t = transform_L(L_train, pepper=p)\n",
    "#     L_d = transform_L(L_dev, pepper=0) # NOTE: p = 0 here\n",
    "#     ch = ClassHierarchy(L_t, task_to_lfs, [], [2])\n",
    "#     for l2 in [0.1, 0.25, 0.5, 1]:\n",
    "#         print(\"p = {}, l2 = {}\".format(p, l2))\n",
    "#         ch.train(n_steps=N_STEPS, step_size=0.1, print_at=100, l2=l2, random_init=False)\n",
    "#         pr, re, f1 = ch.f1_score(L_d, gold_dev)\n",
    "#         print(pr, re, f1)\n",
    "#         print(\"\")\n",
    "#         if f1 > best[2]:\n",
    "#             best = (pr, re, f1)\n",
    "#             opt_config = (p, l2)\n",
    "\n",
    "\n",
    "# print(\"BEST MODEL:\")\n",
    "# print(\"p = {}, l2 = {}\".format(*opt_config))\n",
    "# print best\n",
    "# p, l2 = opt_config\n",
    "# L_t = transform_L(L_train, pepper=p)\n",
    "# ch = ClassHierarchy(L_t, task_to_lfs, [], [2])\n",
    "# ch.train(n_steps=N_STEPS, step_size=0.1, print_at=100, l2=l2, random_init=False)\n",
    "# pr, re, f1 = ch.f1_score(L_d, gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# marginals = ch.conditional_probs(ch._parse_L(L_t), 0)[1]\n",
    "# plt.hist(marginals)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from snorkel.contrib.pipelines.utils import score_marginals\n",
    "\n",
    "# display = False\n",
    "# for l2 in [0, 0.25, 0.5]:\n",
    "#     ch.train(n_steps=1000, step_size=0.1, print_at=100, l2=l2)\n",
    "#     marginals = ch.conditional_probs(ch._parse_L(L_train), 0)[1]\n",
    "#     accuracies = ch.LF_accs(0)\n",
    "#     dev_marginals = ch.conditional_probs(ch._parse_L(L_dev), 0)[1]\n",
    "#     score_marginals(dev_marginals, L_gold_dev, b=0.5)\n",
    "#     if display:\n",
    "#         plt.hist(marginals)\n",
    "#         plt.show()\n",
    "#         plt.hist(accuracies)\n",
    "#         plt.show()\n",
    "#         plt.hist(dev_marginals)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# marginals = ch.conditional_probs(ch._parse_L(L_train), 0)[2]\n",
    "# pipe.train_marginals = marginals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End Metal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pipe.gen_model.learned_lf_stats()['Accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time pipe.supervise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%time pipe.classify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w, b = pipe.disc_model.get_weights()\n",
    "top_w = sorted(zip(w, range(len(w))), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_feature_matrix\n",
    "\n",
    "X_train = load_feature_matrix(pipe.session, split=pipe.config['traditional_split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for (w, idx) in top_w[:100]:\n",
    "    f = X_train.get_key(pipe.session, idx)\n",
    "    print(w, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep for Chris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from scipy.sparse import save_npz\n",
    "\n",
    "# L_train = load_label_matrix(pipe.session, split=TRAIN)\n",
    "# save_npz('L_train', L_train)\n",
    "\n",
    "# L_dev = load_label_matrix(pipe.session, split=DEV)\n",
    "# save_npz('L_dev', L_dev)\n",
    "\n",
    "# L_gold_dev = load_gold_labels(pipe.session, annotator_name='gold', split=DEV)\n",
    "# save_npz('L_gold_dev', L_gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# m = L.shape[1]\n",
    "# counts = np.zeros((m,m))\n",
    "# X = np.zeros((m,m))\n",
    "# arrays = [np.squeeze(L[:,i].toarray()) for i in range(L.shape[1])]\n",
    "# foo = 0\n",
    "# for i in range(m):\n",
    "#     for j in range(i, m):\n",
    "#         r = arrays[i]\n",
    "#         t = arrays[j]\n",
    "#         prod = np.multiply(r,t)\n",
    "#         agree = sum(prod == 1)\n",
    "#         disag = sum(prod == -1)\n",
    "# #         print(\"{} {} {}\".format(prod, agree, disag))\n",
    "#         total = agree + disag\n",
    "#         counts[i,j] = total\n",
    "#         counts[i,j] = total\n",
    "#         if i < j:\n",
    "#             foo += disag\n",
    "#         if not total:\n",
    "#             X[i,j] = 0\n",
    "#         else:\n",
    "#             X[i,j] = 1.0/total * (agree - disag)\n",
    "#             X[j,i] = 1.0/total * (agree - disag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.save('X', X)\n",
    "# np.save('counts', counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def save_sparse_csr(filename, array):\n",
    "#     np.savez(filename, data=array.data, indices=array.indices,\n",
    "#              indptr=array.indptr, shape=array.shape)\n",
    "\n",
    "# def load_sparse_csr(filename):\n",
    "#     loader = np.load(filename)\n",
    "#     return csr_matrix((loader['data'], loader['indices'], loader['indptr']),\n",
    "#                       shape=loader['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filename = \"my_L\"\n",
    "# save_sparse_csr(filename, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "foo = ('.root', ('.label', ('.bool', True), ('.call', ('.in', 5))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "foos = str(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bar = eval(foos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
